#!/usr/bin/env python3
"""Athena ë¶„ì„ í™˜ê²½ í†µí•© ì„¤ì • ìŠ¤í¬ë¦½íŠ¸"""

import boto3
import time
from datetime import datetime

REGIONS = {
    "us-east-1": "US East (N. Virginia)",
    "us-west-2": "US West (Oregon)",
    "eu-central-1": "Europe (Frankfurt)",
    "ap-northeast-1": "Asia Pacific (Tokyo)",
    "ap-northeast-2": "Asia Pacific (Seoul)",
    "ap-southeast-1": "Asia Pacific (Singapore)"
}

def get_account_id():
    return boto3.client('sts').get_caller_identity()['Account']

def create_bucket_if_not_exists(s3_client, bucket_name, region):
    """S3 ë²„í‚· ìƒì„± (ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°)"""
    try:
        if region == 'us-east-1':
            s3_client.create_bucket(Bucket=bucket_name)
        else:
            s3_client.create_bucket(
                Bucket=bucket_name,
                CreateBucketConfiguration={'LocationConstraint': region}
            )
        print(f"âœ… S3 ë²„í‚· ìƒì„±: {bucket_name}")
    except Exception as e:
        if "BucketAlreadyExists" in str(e) or "BucketAlreadyOwnedByYou" in str(e):
            print(f"â„¹ï¸  ë²„í‚· ì¡´ì¬: {bucket_name}")
        else:
            print(f"âŒ ë²„í‚· ìƒì„± ì‹¤íŒ¨: {e}")
            raise

def create_glue_resource(glue_client, resource_type, name, config):
    """Glue ë¦¬ì†ŒìŠ¤ ìƒì„± (ë°ì´í„°ë² ì´ìŠ¤ ë˜ëŠ” í…Œì´ë¸”)"""
    try:
        if resource_type == 'database':
            glue_client.create_database(DatabaseInput=config)
        else:
            glue_client.create_table(**config)
        print(f"âœ… Glue {resource_type} ìƒì„±: {name}")
    except Exception as e:
        if "AlreadyExistsException" in str(e):
            print(f"â„¹ï¸  {resource_type} ì¡´ì¬: {name}")
        else:
            print(f"âŒ {resource_type} ìƒì„± ì‹¤íŒ¨: {e}")

def execute_athena_query(athena_client, query, database, output_location):
    """Athena ì¿¼ë¦¬ ì‹¤í–‰"""
    response = athena_client.start_query_execution(
        QueryString=query,
        QueryExecutionContext={'Database': database},
        ResultConfiguration={'OutputLocation': output_location}
    )
    return response['QueryExecutionId']

def wait_for_query(athena_client, query_id, timeout=30):
    """Athena ì¿¼ë¦¬ ì™„ë£Œ ëŒ€ê¸°"""
    for _ in range(timeout):
        result = athena_client.get_query_execution(QueryExecutionId=query_id)
        status = result['QueryExecution']['Status']['State']
        if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:
            return status
        time.sleep(1)
    return 'TIMEOUT'

def setup_region(region, account_id):
    """ë‹¨ì¼ ë¦¬ì „ ì„¤ì •"""
    print(f"\nğŸ”§ {region} ì„¤ì • ì¤‘...")
    
    # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    s3 = boto3.client('s3', region_name=region)
    glue = boto3.client('glue', region_name=region)
    athena = boto3.client('athena', region_name=region)
    bedrock = boto3.client('bedrock', region_name=region)
    
    # ë²„í‚·ëª…
    analytics_bucket = f"bedrock-analytics-{account_id}-{region}"
    
    # 1. Analytics ë²„í‚· ìƒì„±
    create_bucket_if_not_exists(s3, analytics_bucket, region)
    
    # 2. Glue ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    create_glue_resource(glue, 'database', 'bedrock_analytics', {
        'Name': 'bedrock_analytics',
        'Description': f'Bedrock Model Invocation Logs Database for {region}'
    })
    
    # 3. Bedrock ë¡œê¹… ì„¤ì • í™•ì¸ ë° í…Œì´ë¸” ìƒì„±
    try:
        config = bedrock.get_model_invocation_logging_configuration()
        s3_config = config.get('loggingConfig', {}).get('s3Config', {})
        
        if s3_config:
            log_bucket = s3_config.get('bucketName')
            log_prefix = s3_config.get('keyPrefix', 'bedrock-logs/')
            
            # Glue í…Œì´ë¸” ìƒì„±
            create_glue_resource(glue, 'table', 'bedrock_invocation_logs', {
                'DatabaseName': 'bedrock_analytics',
                'TableInput': {
                    'Name': 'bedrock_invocation_logs',
                    'StorageDescriptor': {
                        'Columns': [
                            {'Name': 'timestamp', 'Type': 'string'},
                            {'Name': 'accountid', 'Type': 'string'},
                            {'Name': 'region', 'Type': 'string'},
                            {'Name': 'modelid', 'Type': 'string'},
                            {'Name': 'identity', 'Type': 'struct<arn:string>'},
                            {'Name': 'input', 'Type': 'struct<inputTokenCount:int>'},
                            {'Name': 'output', 'Type': 'struct<outputTokenCount:int>'}
                        ],
                        'Location': f's3://{log_bucket}/{log_prefix}',
                        'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat',
                        'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',
                        'SerdeInfo': {'SerializationLibrary': 'org.openx.data.jsonserde.JsonSerDe'}
                    },
                    'PartitionKeys': [
                        {'Name': 'year', 'Type': 'string'},
                        {'Name': 'month', 'Type': 'string'},
                        {'Name': 'day', 'Type': 'string'}
                    ]
                }
            })
            
            # 4. íŒŒí‹°ì…˜ ì¶”ê°€
            today = datetime.now()
            year, month, day = today.strftime('%Y'), today.strftime('%m'), today.strftime('%d')
            
            partition_query = f"""
            ALTER TABLE bedrock_analytics.bedrock_invocation_logs 
            ADD IF NOT EXISTS PARTITION (year='{year}', month='{month}', day='{day}')
            LOCATION 's3://{log_bucket}/AWSLogs/{account_id}/BedrockModelInvocationLogs/{region}/{year}/{month}/{day}/'
            """
            
            query_id = execute_athena_query(athena, partition_query, 'bedrock_analytics', 
                                          f's3://{analytics_bucket}/query-results/')
            print(f"âœ… íŒŒí‹°ì…˜ ì¶”ê°€: {year}/{month}/{day}")
            
            # 5. ë°ì´í„° í…ŒìŠ¤íŠ¸
            test_query = f"""
            SELECT COUNT(*) as total_records
            FROM bedrock_analytics.bedrock_invocation_logs 
            WHERE year='{year}' AND month='{month}' AND day='{day}'
            """
            
            query_id = execute_athena_query(athena, test_query, 'bedrock_analytics',
                                          f's3://{analytics_bucket}/query-results/')
            
            if wait_for_query(athena, query_id) == 'SUCCEEDED':
                results = athena.get_query_results(QueryExecutionId=query_id)
                if len(results['ResultSet']['Rows']) > 1:
                    count = results['ResultSet']['Rows'][1]['Data'][0]['VarCharValue']
                    print(f"âœ… ë°ì´í„° í™•ì¸: {count}ê°œ ë ˆì½”ë“œ")
                else:
                    print(f"âš ï¸  ë°ì´í„° ì—†ìŒ")
            else:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤íŒ¨")
                
        else:
            print(f"âš ï¸  Bedrock ë¡œê¹… ë¯¸ì„¤ì •")
            
    except Exception as e:
        print(f"âš ï¸  Bedrock ì„¤ì • í™•ì¸ ì‹¤íŒ¨: {e}")

def main():
    print("ğŸš€ Athena ë¶„ì„ í™˜ê²½ í†µí•© ì„¤ì • ì‹œì‘...")
    
    account_id = get_account_id()
    print(f"ğŸ“ Account ID: {account_id}")
    
    for region in REGIONS.keys():
        try:
            setup_region(region, account_id)
        except Exception as e:
            print(f"âŒ {region} ì„¤ì • ì‹¤íŒ¨: {e}")
    
    print("\nâœ… ëª¨ë“  ì„¤ì • ì™„ë£Œ!")

if __name__ == "__main__":
    main()
